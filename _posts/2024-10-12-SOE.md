---
title: '[Research Introduction]: 
Students rather than experts: a new ai for education pipeline to model more human-like and personalised early adolescences'
data: 2024-10-12
categories: [Our Research]
tags: [LLM-bsed Virtual Student Agents]
image: ../assets/image/2024-10-12/logo_01.jpg
---


<h1 style="text-align: center;">
  <img src="../assets/image/2024-10-12/image.png" alt="Image" width="60" style="vertical-align: super;">Students rather than experts: a new ai for education pipeline to model more human-like and personalised early adolescences
</h1>
<img width="100%" alt="image" src="../assets/image/2024-10-12/SOE_pipline.png"> 

## What does our work focus on?
The capabilities of large language models (LLMs) have been applied in expert systems across various domains, providing new opportunities for AI in Education (AI4Education). Educational interactions involve a cyclical exchange between teachers and students. Current research predominantly focuses on using LLMs to simulate teachers, leveraging their expertise to enhance student learning outcomes. However, the simulation of students, which could improve teachers' instructional skills, has received insufficient attention due to the challenges of modeling and evaluating virtual students. This research poses the question: ***Can LLMs be utilized to develop virtual student agents that mimic human-like performance and individual variability?***" Unlike expert systems focusing on knowledge delivery, virtual students must replicate learning difficulties, emotional responses, and linguistic uncertainties. These traits present significant challenges in both modeling and evaluation. To address these issues, this study focuses on language learning as a context for modeling virtual student agents. We propose a novel AI4Education framework, termed **SOE** (**S**cene - **O**bject - **E**valuation), to systematically construct **LVSA** (**L**LM-based **V**irtual **S**tudent **A**gents). By curating a dataset of personalized teacher-student interactions with various personality traits, question types, and learning stages, and fine-tuning LLMs using LoRA, we conduct multi-dimensional evaluation experiments. 

#### Our Contributions
- ✨ Develop a theoretical framework for generating LVSA: We proposed a comprehensive framework for constructing virtual student agents with scientific rigor and feasibility. This framework extends from conceptual theory, which is the implicit and explicit characteristics of early adolescent students, to operational theory, which is the classification criteria for constructing teacher-student dialogues;
- ✨ Integrate human subjective evaluation metrics into GPT-4 assessments, demonstrating a strong correlation between human evaluators and GPT-4 in judging LVSA authenticity: We invited ten human evaluators to conduct Turing tests, distinguishing between the LVSA and real students. After the tests, we incorporated human subjective metrics into GPT-4’s evaluation pipeline to align with human assessments of virtual student authenticity;
- ✨ Validate that LLMs can generate human-like, personalized virtual student agents in educational contexts, laying a foundation for future applications in pre-service teacher training and multi-agent simulation environments.


## More information will be released on website
https://marsgemini.github.io/SOE-LVSA/

